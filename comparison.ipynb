{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5454c8ea",
   "metadata": {},
   "source": [
    "The Isotonic Regression model is a type of continuous step-function where a free-form flat line is fitted to minimize error between the observed points. Specifically it minimizes the sum of squared errors between predicted and observed points. Also, the model ensures that the slope of inputs and outputs are never in opposite sign (one can't be increasing while the other decreases), i.e. monotonic. I chose this model just because I only looked into two models and this one seemed more interesting and just a bit easier to understand. One of the downsides of this model is it only takes one feature though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29a0f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from binary_classification import load_data\n",
    "\n",
    "\n",
    "def train_isotonic():\n",
    "    # Load dataset\n",
    "    X_train, X_test, y_train, y_test, feature_names = load_data()\n",
    "\n",
    "    # Convert torch tensors to numpy\n",
    "    X_train = X_train.numpy()\n",
    "    X_test = X_test.numpy()\n",
    "    y_train = y_train.numpy()\n",
    "    y_test = y_test.numpy()\n",
    "\n",
    "    # IsotonicRegression takes 1d input (so using first feature only)\n",
    "    X_train_1d = X_train[:, 0]\n",
    "    X_test_1d = X_test[:, 0]\n",
    "\n",
    "    # model\n",
    "    iso_model = IsotonicRegression(out_of_bounds=\"clip\")\n",
    "    iso_model.fit(X_train_1d, y_train)\n",
    "\n",
    "    # Predict\n",
    "    y_train_pred = iso_model.predict(X_train_1d)\n",
    "    y_test_pred = iso_model.predict(X_test_1d)\n",
    "\n",
    "    # Convert regression output to binary class\n",
    "    y_train_pred_class = (y_train_pred >= 0.5).astype(int)\n",
    "    y_test_pred_class = (y_test_pred >= 0.5).astype(int)\n",
    "\n",
    "    # Accuracy\n",
    "    train_acc = accuracy_score(y_train, y_train_pred_class)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred_class)\n",
    "\n",
    "    print(f\"Training Accuracy: {train_acc:.3f}\")\n",
    "    print(f\"Test Accuracy:     {test_acc:.3f}\")\n",
    "\n",
    "    return iso_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f4e9b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.629\n",
      "Test Accuracy:     0.623\n"
     ]
    }
   ],
   "source": [
    "model = train_isotonic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2162f63",
   "metadata": {},
   "source": [
    "The isotonic regression model performed much poorer than the logistic regression model (63% training and test accuracy for isotonic compared to 99% for logistic). I think it probably has to do with the number of features being reduced, but nonetheless I still think it performed much better than expected (still more than half accurate with over 90% less features)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
